{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import all the required modules."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge this with the main.pynb file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "Error",
     "evalue": "gst_parse_error: no element \"nvjpegenc\" (1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mError\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32m/home/anthrax/Projects/Avnish/Robo-Sapiens-AutoBot/main.ipynb Cell 3'\u001b[0m in \u001b[0;36m<cell line: 12>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/anthrax/Projects/Avnish/Robo-Sapiens-AutoBot/main.ipynb#ch0000002?line=9'>10</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mAlexnet\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/anthrax/Projects/Avnish/Robo-Sapiens-AutoBot/main.ipynb#ch0000002?line=10'>11</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtime\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/anthrax/Projects/Avnish/Robo-Sapiens-AutoBot/main.ipynb#ch0000002?line=11'>12</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mjetbot\u001b[39;00m \u001b[39mimport\u001b[39;00m Robot\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/anthrax/Projects/Avnish/Robo-Sapiens-AutoBot/main.ipynb#ch0000002?line=12'>13</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m \u001b[39mimport\u001b[39;00m convert_to_tensor, expand_dims, uint8\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/anthrax/Projects/Avnish/Robo-Sapiens-AutoBot/main.ipynb#ch0000002?line=13'>14</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorchsummary\u001b[39;00m \u001b[39mimport\u001b[39;00m summary\n",
      "File \u001b[0;32m~/Projects/Avnish/Robo-Sapiens-AutoBot/jetbot/__init__.py:5\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      <a href='file:///home/anthrax/Projects/Avnish/Robo-Sapiens-AutoBot/jetbot/__init__.py?line=2'>3</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mmotor\u001b[39;00m \u001b[39mimport\u001b[39;00m Motor\n\u001b[1;32m      <a href='file:///home/anthrax/Projects/Avnish/Robo-Sapiens-AutoBot/jetbot/__init__.py?line=3'>4</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mrobot\u001b[39;00m \u001b[39mimport\u001b[39;00m Robot\n\u001b[0;32m----> <a href='file:///home/anthrax/Projects/Avnish/Robo-Sapiens-AutoBot/jetbot/__init__.py?line=4'>5</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mimage\u001b[39;00m \u001b[39mimport\u001b[39;00m bgr8_to_jpeg\n\u001b[1;32m      <a href='file:///home/anthrax/Projects/Avnish/Robo-Sapiens-AutoBot/jetbot/__init__.py?line=5'>6</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mobject_detection\u001b[39;00m \u001b[39mimport\u001b[39;00m ObjectDetector\n",
      "File \u001b[0;32m~/Projects/Avnish/Robo-Sapiens-AutoBot/jetbot/image.py:6\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      <a href='file:///home/anthrax/Projects/Avnish/Robo-Sapiens-AutoBot/jetbot/image.py?line=1'>2</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mcv2\u001b[39;00m\n\u001b[1;32m      <a href='file:///home/anthrax/Projects/Avnish/Robo-Sapiens-AutoBot/jetbot/image.py?line=2'>3</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mjpeg_encoder\u001b[39;00m \u001b[39mimport\u001b[39;00m JpegEncoder\n\u001b[0;32m----> <a href='file:///home/anthrax/Projects/Avnish/Robo-Sapiens-AutoBot/jetbot/image.py?line=5'>6</a>\u001b[0m _ENCODER \u001b[39m=\u001b[39m JpegEncoder(width\u001b[39m=\u001b[39;49m\u001b[39m224\u001b[39;49m, height\u001b[39m=\u001b[39;49m\u001b[39m224\u001b[39;49m, fps\u001b[39m=\u001b[39;49m\u001b[39m21\u001b[39;49m)\n\u001b[1;32m      <a href='file:///home/anthrax/Projects/Avnish/Robo-Sapiens-AutoBot/jetbot/image.py?line=8'>9</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mbgr8_to_jpeg_gst\u001b[39m(value):\n\u001b[1;32m     <a href='file:///home/anthrax/Projects/Avnish/Robo-Sapiens-AutoBot/jetbot/image.py?line=9'>10</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m _ENCODER\u001b[39m.\u001b[39mencode(value)\n",
      "File \u001b[0;32m~/Projects/Avnish/Robo-Sapiens-AutoBot/jetbot/jpeg_encoder.py:34\u001b[0m, in \u001b[0;36mJpegEncoder.__init__\u001b[0;34m(self, width, height, fps)\u001b[0m\n\u001b[1;32m     <a href='file:///home/anthrax/Projects/Avnish/Robo-Sapiens-AutoBot/jetbot/jpeg_encoder.py?line=18'>19</a>\u001b[0m CAPS \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mvideo/x-raw,format=BGR,width=\u001b[39m\u001b[39m{width}\u001b[39;00m\u001b[39m,height=\u001b[39m\u001b[39m{height}\u001b[39;00m\u001b[39m,framerate=\u001b[39m\u001b[39m{fps}\u001b[39;00m\u001b[39m/1\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m     <a href='file:///home/anthrax/Projects/Avnish/Robo-Sapiens-AutoBot/jetbot/jpeg_encoder.py?line=19'>20</a>\u001b[0m     width\u001b[39m=\u001b[39mwidth,\n\u001b[1;32m     <a href='file:///home/anthrax/Projects/Avnish/Robo-Sapiens-AutoBot/jetbot/jpeg_encoder.py?line=20'>21</a>\u001b[0m     height\u001b[39m=\u001b[39mheight,\n\u001b[1;32m     <a href='file:///home/anthrax/Projects/Avnish/Robo-Sapiens-AutoBot/jetbot/jpeg_encoder.py?line=21'>22</a>\u001b[0m     fps\u001b[39m=\u001b[39mfps\n\u001b[1;32m     <a href='file:///home/anthrax/Projects/Avnish/Robo-Sapiens-AutoBot/jetbot/jpeg_encoder.py?line=22'>23</a>\u001b[0m )\n\u001b[1;32m     <a href='file:///home/anthrax/Projects/Avnish/Robo-Sapiens-AutoBot/jetbot/jpeg_encoder.py?line=24'>25</a>\u001b[0m GST_STRING \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mappsrc name=src emit-signals=True is-live=True caps=video/x-raw,format=BGR,width=\u001b[39m\u001b[39m{width}\u001b[39;00m\u001b[39m,height=\u001b[39m\u001b[39m{height}\u001b[39;00m\u001b[39m,framerate=\u001b[39m\u001b[39m{fps}\u001b[39;00m\u001b[39m/1 !\u001b[39m\u001b[39m'\u001b[39m\\\n\u001b[1;32m     <a href='file:///home/anthrax/Projects/Avnish/Robo-Sapiens-AutoBot/jetbot/jpeg_encoder.py?line=25'>26</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39m nvjpegenc \u001b[39m\u001b[39m'\u001b[39m\\\n\u001b[1;32m     <a href='file:///home/anthrax/Projects/Avnish/Robo-Sapiens-AutoBot/jetbot/jpeg_encoder.py?line=26'>27</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39m! image/jpeg,width=\u001b[39m\u001b[39m{width}\u001b[39;00m\u001b[39m,height=\u001b[39m\u001b[39m{height}\u001b[39;00m\u001b[39m,framerate=\u001b[39m\u001b[39m{fps}\u001b[39;00m\u001b[39m/1 !\u001b[39m\u001b[39m'\u001b[39m\\\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='file:///home/anthrax/Projects/Avnish/Robo-Sapiens-AutoBot/jetbot/jpeg_encoder.py?line=30'>31</a>\u001b[0m     fps\u001b[39m=\u001b[39mfps\n\u001b[1;32m     <a href='file:///home/anthrax/Projects/Avnish/Robo-Sapiens-AutoBot/jetbot/jpeg_encoder.py?line=31'>32</a>\u001b[0m )\n\u001b[0;32m---> <a href='file:///home/anthrax/Projects/Avnish/Robo-Sapiens-AutoBot/jetbot/jpeg_encoder.py?line=33'>34</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpipeline \u001b[39m=\u001b[39m Gst\u001b[39m.\u001b[39;49mparse_launch(GST_STRING)\n\u001b[1;32m     <a href='file:///home/anthrax/Projects/Avnish/Robo-Sapiens-AutoBot/jetbot/jpeg_encoder.py?line=34'>35</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mappsrc \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpipeline\u001b[39m.\u001b[39mget_by_name(\u001b[39m'\u001b[39m\u001b[39msrc\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     <a href='file:///home/anthrax/Projects/Avnish/Robo-Sapiens-AutoBot/jetbot/jpeg_encoder.py?line=36'>37</a>\u001b[0m appsink \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpipeline\u001b[39m.\u001b[39mget_by_name(\u001b[39m'\u001b[39m\u001b[39msink\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[0;31mError\u001b[0m: gst_parse_error: no element \"nvjpegenc\" (1)"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pylab as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.models as models\n",
    "import Alexnet\n",
    "import time\n",
    "from jetbot import Robot\n",
    "from tensorflow import convert_to_tensor, expand_dims, uint8\n",
    "from torchsummary import summary\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize the class instance as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "robot = Robot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Function definitions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(path, out):\n",
    "    model = Alexnet.alexnet(pretrained=True)\n",
    "\n",
    "    model.classifier = nn.Sequential(\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(256 * 6 * 6, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(4096, out)\n",
    "        )\n",
    "\n",
    "    model.load_state_dict(torch.load(path))\n",
    "    return model\n",
    "\n",
    "\n",
    "def region_of_interest(img, vertices):\n",
    "    mask = np.zeros_like(img)\n",
    "    #channel_count = img.shape[2]\n",
    "    match_mask_color = 255\n",
    "    cv2.fillPoly(mask, vertices, match_mask_color)\n",
    "    masked_image = cv2.bitwise_and(img, mask)\n",
    "    return masked_image\n",
    "\n",
    "\n",
    "def drow_the_lines(img, lines):\n",
    "    img = np.copy(img)\n",
    "    blank_image = np.zeros((img.shape[0], img.shape[1], 3), dtype=np.uint8)\n",
    "\n",
    "    try:\n",
    "        for line in lines:\n",
    "            for x1, y1, x2, y2 in line:\n",
    "                cv2.line(blank_image, (x1,y1), (x2,y2), (0, 255, 0), thickness=10)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    img = cv2.addWeighted(img, 0.8, blank_image, 1, 0.0)\n",
    "    return img\n",
    "\n",
    "\n",
    "def process(image):\n",
    "    print(image.shape)\n",
    "    height = image.shape[0]\n",
    "    width = image.shape[1]\n",
    "    region_of_interest_vertices = [\n",
    "        (0, height-10),\n",
    "        (0, height/2),\n",
    "        (height-10, height/2),\n",
    "        (height-10, height-10)\n",
    "    ]\n",
    "    gray_image = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "    canny_image = cv2.Canny(gray_image, 100, 120)\n",
    "    cropped_image = region_of_interest(canny_image,\n",
    "                    np.array([region_of_interest_vertices], np.int32),)\n",
    "    lines = cv2.HoughLinesP(cropped_image,\n",
    "                            rho=2,\n",
    "                            theta=np.pi/180,\n",
    "                            threshold=70,\n",
    "                            lines=np.array([]),\n",
    "                            minLineLength=30,\n",
    "                            maxLineGap=100)\n",
    "    image_with_lines = drow_the_lines(image, lines)\n",
    "    return image_with_lines\n",
    "\n",
    "\n",
    "\n",
    "def getProbability(image, detectors):\n",
    "    prob = []\n",
    "    \n",
    "    output = F.softmax(detectors[0](image))\n",
    "    if max(output) > 0.7:\n",
    "\n",
    "        p = np.argmax(output.detach().numpy())\n",
    "        if(p == 0):\n",
    "            prob.append('person')\n",
    "        elif(p == 1):\n",
    "            prob.append('animal')\n",
    "        else:\n",
    "            prob.append('roadCones')\n",
    "    else:\n",
    "        prob.append('Nothing')\n",
    "\n",
    "    output = F.softmax(detectors[1](image))\n",
    "    if max(output) > 0.7:\n",
    "\n",
    "        p = np.argmax(output.detach().numpy())\n",
    "        if(p == 0):\n",
    "            prob.append('Stop')\n",
    "        elif(p == 1):\n",
    "            prob.append('Blue')\n",
    "        elif(p == 1):\n",
    "            prob.append('Red')\n",
    "        else:\n",
    "            prob.append('Green')\n",
    "    else:\n",
    "        prob.append('Nothing')\n",
    "\n",
    "    output = detectors[2](image)\n",
    "    p = F.softmax(output)\n",
    "    if p[0] > 0.67:\n",
    "        prob.append(1)\n",
    "    else:\n",
    "        prob.append(0)\n",
    "    return prob\n",
    "\n",
    "def stop(t, halt):\n",
    "    then = time.time()\n",
    "    if not halt:\n",
    "        then = time.time()\n",
    "        halt = True\n",
    "    elif now - then < t:\n",
    "        robot.stop()\n",
    "    else:\n",
    "        halt = False\n",
    "    return halt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Main Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "width = 224\n",
    "height = 224\n",
    "\n",
    "path = [\"./72.4(Alexnet).pth\", \"./stop_and_traffic(65.7).pth\",\"./zebra.pth\"]\n",
    "detectors = []\n",
    "\n",
    "detectors.append(get_model(path[0], 3))\n",
    "detectors.append(get_model(path[1], 4))\n",
    "detectors.append(get_model(path[2], 2))\n",
    "\n",
    "frameCount = 0\n",
    "timeNow = time.time()\n",
    "\n",
    "halt = False\n",
    "\n",
    "t = 0\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    img = cv2.resize(frame, (width , height ))\n",
    "    rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    rgb_tensor = torch.Tensor(rgb)\n",
    "    rgb_tensor = torch.permute(rgb_tensor,(2,0,1))\n",
    "    # rgb_tensor = convert_to_tensor(rgb, dtype=uint8)                      # commented now hgfs\n",
    "    # rgb_tensor = expand_dims(rgb_tensor , 0)\n",
    "\n",
    "    # print(\"=>\", rgb_tensor)\n",
    "    # print(\"=>\", detectors)\n",
    "    pred = getProbability(rgb_tensor, detectors)\n",
    "\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    # frame = cv2.putText(frame, f'A {pred[0]:.2f}', (20, 20), font, 1, (25, 25, 25), 2, cv2.LINE_AA)\n",
    "    # frame = cv2.putText(frame, f'B {pred[1]:.2f}', (20, 50), font, 1, (25, 25, 25), 2, cv2.LINE_AA)\n",
    "    # frame = cv2.putText(frame, f'C: {pred[2]:.2f}', (20, 80), font, 1, (25, 25, 25), 2, cv2.LINE_AA)\n",
    "    frame = cv2.putText(frame, f'D: {pred[0]}', (20, 50), font, 1, (25, 25, 25), 2, cv2.LINE_AA)\n",
    "    frame = cv2.putText(frame, f'D: {pred[1]:.2f}', (20, 110), font, 1, (25, 25, 25), 2, cv2.LINE_AA)\n",
    "\n",
    "    if halt:\n",
    "        halt = stop(t, halt)\n",
    "    else:\n",
    "        # For stop sign\n",
    "        if(pred[1] == \"Stop\"):\n",
    "            print(\"reached destination\")\n",
    "            exit()\n",
    "        \n",
    "        if (pred[2] == 1):\n",
    "            print(\"waiting for 2 second\")\n",
    "            t = 2\n",
    "            halt = stop(t, halt)\n",
    "\n",
    "        if (pred[0] == \"person\"):\n",
    "            print(\"person detected, witing for 6 sec.\")\n",
    "            t = 6\n",
    "            halt = stop(t, halt)\n",
    "\n",
    "        if (pred[0] == \"animal\"):\n",
    "            print(\"animal detected, witing for 10 sec.\")\n",
    "            t = 10\n",
    "            halt = stop(t, halt)\n",
    "\n",
    "        if (pred[1] != \"Nothing\"):\n",
    "            if (pred[1] == \"Red\"):\n",
    "                print(\"wait for 1 sec.\")\n",
    "                t = 1\n",
    "                halt = stop(t, halt)\n",
    "            elif (pred[1] == \"Green\"):\n",
    "                print(\"starting the bot to run.\")\n",
    "                robot.forward(0.5)\n",
    "\n",
    "            \n",
    "        if (pred[2] == 1):\n",
    "            now = time.time()\n",
    "            t = 2\n",
    "            halt = stop(t, halt)\n",
    "\n",
    "        if (pred[1] == \"Red\"):\n",
    "            print(\"wait for 1 sec.\")\n",
    "            t = 1\n",
    "            halt = stop(t, halt)\n",
    "       \n",
    "    frame = process(frame)\n",
    "    cv2.imshow('frame', frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e2e4e781fd14e506a89e02ef0400b503ca6c2873edb86a58c5600c24729377d3"
  },
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
